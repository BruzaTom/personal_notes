## ğŸ“š TL;DR â€” Free Programming Books Cache & Tracker

Build a local library from the `free-programming-books` repo:
- ğŸ—‚ï¸ Parse Markdown files to extract direct PDF/HTML links
- ğŸ“¥ Download resources into organized folders (by language/topic)
- ğŸ§  Store metadata (title, author, format, tags) in JSON or SQLite
- ğŸ“Š Track reading progress, milestones, and timestamps
- ğŸ›ï¸ Optional GUI/CLI to browse, search, and log cycles
- ğŸ¨ Integrate with planner/dashboard for ritualized reading flow

dev-library/
â”œâ”€â”€ books/
â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â”œâ”€â”€ Automate_the_Boring_Stuff.pdf
â”‚   â”‚   â””â”€â”€ metadata.json
â”‚   â”œâ”€â”€ algorithms/
â”‚   â”‚   â”œâ”€â”€ Introduction_to_Algorithms.pdf
â”‚   â”‚   â””â”€â”€ metadata.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ metadata/
â”‚   â””â”€â”€ index.json         # Global metadata index
â”œâ”€â”€ progress/
â”‚   â””â”€â”€ reading-log.json   # Tracks status, milestones, timestamps
â””â”€â”€ scripts/
    â””â”€â”€ fetch_books.py     # Parser + downloader

ğŸ§  Starter Parser: fetch_books.py

This script:

    Parses a Markdown file

    Extracts direct PDF links

    Downloads them

    Stores metadata

import os, re, requests, json
from urllib.parse import urlparse

MD_FILE = "free-programming-books.md"
LIBRARY_DIR = "dev-library/books"
METADATA_INDEX = "dev-library/metadata/index.json"

def sanitize_filename(title):
    return re.sub(r'[^\w\s-]', '', title).strip().replace(' ', '_')

def extract_links(md_path):
    with open(md_path, "r", encoding="utf-8") as f:
        lines = f.readlines()
    books = []
    for line in lines:
        match = re.match(r"\* 

\[(.+?)\]

\((https?://.+?)\)", line)
        if match and ".pdf" in match.group(2):
            books.append({
                "title": match.group(1),
                "url": match.group(2),
                "filename": sanitize_filename(match.group(1)) + ".pdf"
            })
    return books

def download_book(book, topic="misc"):
    topic_dir = os.path.join(LIBRARY_DIR, topic)
    os.makedirs(topic_dir, exist_ok=True)
    path = os.path.join(topic_dir, book["filename"])
    try:
        r = requests.get(book["url"], timeout=10)
        with open(path, "wb") as f:
            f.write(r.content)
        print(f"âœ… Downloaded: {book['title']}")
        return True
    except Exception as e:
        print(f"âŒ Failed: {book['title']} â€” {e}")
        return False

def save_metadata(book, topic="misc"):
    index_path = METADATA_INDEX
    os.makedirs(os.path.dirname(index_path), exist_ok=True)
    try:
        if os.path.exists(index_path):
            with open(index_path, "r") as f:
                index = json.load(f)
        else:
            index = []
        book["topic"] = topic
        index.append(book)
        with open(index_path, "w") as f:
            json.dump(index, f, indent=2)
    except Exception as e:
        print(f"âš ï¸ Metadata error: {e}")

if __name__ == "__main__":
    books = extract_links(MD_FILE)
    for book in books[:10]:  # limit for testing
        if download_book(book):
            save_metadata(book)

ğŸ§© Next Steps

    Add fuzzy search or tag filters

    Track reading progress in reading-log.json

    Build a Tkinter GUI with scrollable book list + preview pane

    Integrate splashboard banners for milestones
